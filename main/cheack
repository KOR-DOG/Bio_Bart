from transformers import BartForConditionalGeneration, BartTokenizer

# 경로 수정: 'biobart/model.safetensors' -> 올바른 경로로 수정
model = BartForConditionalGeneration.from_pretrained('./biobart')
tokenizer = BartTokenizer.from_pretrained('./biobart')

def generate_response(input_text):
    inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True, max_length=1024)
    outputs = model.generate(inputs['input_ids'], max_length=150, num_beams=5, early_stopping=True)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

while True:
    user_input = input("You: ")
    if user_input.lower() in ['exit', 'quit']:
        print("Goodbye!")
        break
    response = generate_response(user_input)
    print("Bot:", response)
